{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gjnNY4UvZ9a9"
      },
      "outputs": [],
      "source": [
        "!pip install torchmetrics\n",
        "!pip install wandb\n",
        "!pip install torchsummary\n",
        "!pip install gdown"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "49jiz431yh6l"
      },
      "source": [
        "# Dataset Download"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3f-5nQCyhbIj"
      },
      "outputs": [],
      "source": [
        "!gdown 1bbIy5P_aP_xarxUw4yPuPk4CglHPGLco"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0Ljt17_ihehJ"
      },
      "outputs": [],
      "source": [
        "!gdown 1JH7CQ77wjkV0Xnp14l8u4bqJF0ENGMqp"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b3iTo-cEj7HK"
      },
      "outputs": [],
      "source": [
        "!unzip UDC_train.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bSLshZpbCkQb"
      },
      "outputs": [],
      "source": [
        "!unzip UDC_validation_input.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kPdCevJwmbJJ"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.makedirs('ds/val/GT',exist_ok = True)\n",
        "os.makedirs('ds/val/input',exist_ok = True)\n",
        "os.makedirs('ds/train/GT',exist_ok = True)\n",
        "os.makedirs('ds/train/input',exist_ok = True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mT_sAC8UoxHn"
      },
      "outputs": [],
      "source": [
        "import shutil\n",
        "val_list = sorted(os.listdir('training/GT/'))[:26]\n",
        "for im_name in val_list:\n",
        "  shutil.move(f'training/GT/{im_name}',f'ds/val/GT/{im_name}')\n",
        "for im_name in val_list:\n",
        "  shutil.move(f'training/input/{im_name}',f'ds/val/input/{im_name}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Iwexp_whsoZC"
      },
      "outputs": [],
      "source": [
        "train_list = sorted(os.listdir('training/GT/'))\n",
        "for im_name in train_list:\n",
        "  shutil.move(f'training/GT/{im_name}',f'ds/train/GT/{im_name}')\n",
        "for im_name in train_list:\n",
        "  shutil.move(f'training/input/{im_name}',f'ds/train/input/{im_name}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EIx9No4jaOrK"
      },
      "source": [
        "##### Library import"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "TJCaH25saGGA"
      },
      "outputs": [],
      "source": [
        "import argparse,os,wandb,tqdm\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision.transforms as T\n",
        "from torch.utils.data import Dataset,DataLoader\n",
        "import PIL.Image as Image\n",
        "from torchmetrics import PeakSignalNoiseRatio,StructuralSimilarityIndexMeasure\n",
        "from torchsummary import summary\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iOsPxcNcaT1X"
      },
      "source": [
        "##### Parameter Intilisation\n",
        "* Here we intialise the paramets such as epoch,batch size, train img size etc."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "n2gTfJ7PaRyL"
      },
      "outputs": [],
      "source": [
        "mode = 'train' #['test', 'train']\n",
        "checkpoint_folder ='PDCRN_SYNTH'\n",
        "model_type = 'PDCRN'\n",
        "train_path = 'ds/train'\n",
        "test_path = 'ds/val'\n",
        "batch_size = 48\n",
        "epochs = 1000\n",
        "LR = 1e-4\n",
        "num_filters  = 64\n",
        "dilation_rates = (3, 2, 1, 1, 1, 1)\n",
        "nPyramidFilters = 64\n",
        "log_name = 'logger'\n",
        "in_ch = 3"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2xyS7DhhaXE-"
      },
      "source": [
        "##### Dataset Intialisation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ucDaB-ChaWY6"
      },
      "outputs": [],
      "source": [
        "class Custom_Dataset(Dataset):\n",
        "    def __init__(self,root_dir, is_train=False):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            root_dir (string): Directory with all the images.\n",
        "            transform (callable, optional): Optional transform to be applied\n",
        "                on a sample.\n",
        "        \"\"\"\n",
        "        self.root_dir = root_dir\n",
        "        self.is_train = is_train\n",
        "        self.hq_im_file_list = []\n",
        "        self.lq_im_file_list = []\n",
        "        self.hq_train_files = {}\n",
        "        self.lq_train_files = {}\n",
        "        for dir_path, _, file_names in os.walk(root_dir):\n",
        "            for f_paths in sorted(file_names):\n",
        "                if dir_path.endswith('GT'):\n",
        "                    self.hq_im_file_list.append(os.path.join(dir_path,f_paths))\n",
        "                elif dir_path.endswith('input'):\n",
        "                    self.lq_im_file_list.append(os.path.join(dir_path,f_paths))\n",
        "        for im_names in self.hq_im_file_list:\n",
        "            self.hq_train_files[im_names] = np.load(im_names)\n",
        "        for im_names in self.lq_im_file_list:\n",
        "            self.lq_train_files[im_names] = np.load(im_names)\n",
        "        # self.tensor_convert = T.ToTensor()\n",
        "        self.train_transform = T.Compose(\n",
        "    [T.RandomCrop((512,512)),T.RandomVerticalFlip(p=0.5),T.RandomHorizontalFlip(p=0.5)\\\n",
        "       ,T.RandomAffine((0,360))])\n",
        "\n",
        "        # self.val_transform = T.Compose([T.Normalize([0.5, 0.5, 0.5], [0.5, 0.5, 0.5])])\n",
        "    def __len__(self):\n",
        "        return len(self.hq_im_file_list)\n",
        "    def tone_transform(self,im,c=0.25):\n",
        "      mapped_x = im / (im + c)\n",
        "      return mapped_x\n",
        "    def __getitem__(self, idx):\n",
        "        image_hq_fname = self.hq_train_files[self.hq_im_file_list[idx]]\n",
        "        image_lq_fname = self.lq_train_files[self.lq_im_file_list[idx]]\n",
        "        hq_image = torch.from_numpy(self.tone_transform(image_hq_fname)).unsqueeze(dim=0).permute(0,3,1,2)\n",
        "        lq_image = torch.from_numpy(self.tone_transform(image_lq_fname)).unsqueeze(dim=0).permute(0,3,1,2)\n",
        "        concat_img = torch.cat([hq_image,lq_image],dim=0)\n",
        "        if self.is_train:\n",
        "            image = self.train_transform(concat_img)\n",
        "        else:\n",
        "            # image = self.val_transform(concat_img)\n",
        "            image = concat_img\n",
        "        hq_img,lq_img = image.tensor_split(2)\n",
        "        return lq_img.squeeze(0),hq_img.squeeze(0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FtroVaMValU5"
      },
      "outputs": [],
      "source": [
        "train_ds = Custom_Dataset(train_path,is_train=True)\n",
        "train_dataloader = DataLoader(train_ds,batch_size=batch_size,shuffle=True,num_workers=8)\n",
        "val_ds = Custom_Dataset(test_path,is_train=False)\n",
        "val_dataloader = DataLoader(val_ds,batch_size=1,shuffle=False,num_workers=8)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xRMOPpw4arIq"
      },
      "source": [
        "##### DWT and IWT layer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "14TCHFuzaoHM"
      },
      "outputs": [],
      "source": [
        "class DWT(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(DWT,self).__init__()\n",
        "    def forward(self,input):\n",
        "        x01 = input[:,:,0::2,:] / 4.0\n",
        "        x02 = input[:,:,1::2,:] / 4.0\n",
        "        x1 = x01[:, :,:, 0::2]\n",
        "        x2 = x01[:, :,:, 1::2]\n",
        "        x3 = x02[:, :,:, 0::2]\n",
        "        x4 = x02[:, :,:, 1::2]\n",
        "        y1 = x1+x2+x3+x4\n",
        "        y2 = x1-x2+x3-x4\n",
        "        y3 = x1+x2-x3-x4\n",
        "        y4 = x1-x2-x3+x4\n",
        "        return torch.cat([y1, y2, y3, y4], axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "_iB1SQcoatEm"
      },
      "outputs": [],
      "source": [
        "class IWT(nn.Module):\n",
        "    def __init__(self,scale=2):\n",
        "        super(IWT,self).__init__()\n",
        "        self.upsampler = nn.PixelShuffle(scale)\n",
        "\n",
        "    def kernel_build(self,input_shape):\n",
        "        c = input_shape[1]\n",
        "        out_c = c >> 2\n",
        "        kernel = np.zeros((c, c,1, 1), dtype=np.float32)\n",
        "        for i in range(0, c, 4):\n",
        "            idx = i >> 2\n",
        "            kernel[idx,idx::out_c,0,0]          = [1, 1, 1, 1]\n",
        "            kernel[idx+out_c,idx::out_c,0,0]    = [1,-1, 1,-1]\n",
        "            kernel[idx+out_c*2,idx::out_c,0,0]  = [1, 1,-1,-1]\n",
        "            kernel[idx+out_c*3,idx::out_c,0,0]  = [1,-1,-1, 1]\n",
        "        self.kernel = torch.tensor(data=kernel,dtype=torch.float32,requires_grad=True).to(device)\n",
        "        return None\n",
        "\n",
        "    def forward(self,input):\n",
        "        self.kernel_build(input.shape)\n",
        "        y = nn.functional.conv2d(input,weight = self.kernel, padding='same')\n",
        "        y = self.upsampler(y)\n",
        "        return y"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zoMepuWLaxXD"
      },
      "source": [
        "#### Model Components and Model Intialisation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "_Cf0_OM3avTW"
      },
      "outputs": [],
      "source": [
        "class DilationPyramid(nn.Module):\n",
        "    def __init__(self,num_filters,dilation_rates):\n",
        "        super(DilationPyramid,self).__init__()\n",
        "        self.layer_1 = nn.Conv2d(num_filters,num_filters*2,3,padding='same')\n",
        "        self.layer_2 = nn.Conv2d(num_filters*2,num_filters,3,padding='same',dilation=dilation_rates[0])\n",
        "        self.layer_3 = []\n",
        "        for dil_rate in dilation_rates[1:]:\n",
        "          self.layer_3.append(nn.Conv2d(num_filters,num_filters,3,padding='same',dilation=dil_rate))\n",
        "          self.layer_3.append(nn.ReLU())\n",
        "        self.layer_3 = nn.Sequential(*self.layer_3)\n",
        "        # self.layer_3 = nn.Sequential(*[[nn.Conv2d(num_filters,num_filters,3,padding='same',dilation=dil_rate),nn.ReLU()] for dil_rate in dilation_rates[1:]])\n",
        "        self.layer_4 = nn.Conv2d(num_filters*2,num_filters,1,padding='same')\n",
        "    def forward(self,input):\n",
        "        x = self.layer_1(input)\n",
        "        x = nn.functional.relu(x)\n",
        "        x = self.layer_2(x)\n",
        "        x = self.layer_3(x)\n",
        "        x = torch.cat([input,x],dim=1)\n",
        "        x = self.layer_4(x)\n",
        "        out = nn.functional.relu(x)\n",
        "        return out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "icnF5kADazPv"
      },
      "outputs": [],
      "source": [
        "class PyramidBlock(nn.Module):\n",
        "    def __init__(self,num_filters,dilation_rates,nPyramidFilters):\n",
        "        super(PyramidBlock,self).__init__()\n",
        "        self.feat_extract = nn.Sequential(*[DilationPyramid(nPyramidFilters,dilation_rates),\\\n",
        "        nn.Conv2d(num_filters,num_filters,3,padding='same')])\n",
        "    def forward(self,input):\n",
        "        x = self.feat_extract(input)*0.1\n",
        "        return input+x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "Ai8B5lXIa04v"
      },
      "outputs": [],
      "source": [
        "class UDC_Arc(nn.Module):\n",
        "    def __init__(self,in_ch,num_filters,dilation_rates,nPyramidFilters):\n",
        "        super(UDC_Arc,self).__init__()\n",
        "        self.encoder = nn.Sequential(*nn.ModuleList([DWT(),nn.PixelUnshuffle(downscale_factor=2),\\\n",
        "        nn.Conv2d(in_channels=in_ch*4*4,out_channels=num_filters,kernel_size=5,padding='same'),\\\n",
        "        nn.Conv2d(in_channels=num_filters,out_channels=num_filters,kernel_size=3,padding='same'),\\\n",
        "        PyramidBlock(num_filters,dilation_rates,nPyramidFilters),\\\n",
        "        nn.Conv2d(num_filters,num_filters*2,kernel_size=5,stride=2,padding=2),\\\n",
        "        PyramidBlock(num_filters*2,dilation_rates,nPyramidFilters*2),\\\n",
        "        nn.Conv2d(num_filters*2,num_filters*4,kernel_size=5,stride=2,padding=2),\\\n",
        "        PyramidBlock(num_filters*4,dilation_rates,nPyramidFilters*4)\n",
        "        ]))\n",
        "        self.decoder = nn.Sequential(*nn.ModuleList([PyramidBlock(num_filters*4,dilation_rates,nPyramidFilters*4),\\\n",
        "        nn.ConvTranspose2d(num_filters*4,num_filters*2,kernel_size = 4,stride=2,padding=1),\\\n",
        "        PyramidBlock(num_filters*2,dilation_rates,nPyramidFilters*2),\\\n",
        "        nn.ConvTranspose2d(num_filters*2,num_filters,kernel_size = 4,stride=2,padding=1),\\\n",
        "        PyramidBlock(num_filters,dilation_rates,nPyramidFilters),\\\n",
        "        nn.PixelShuffle(upscale_factor=2),nn.Conv2d(num_filters//4,in_ch*4,3,padding='same'),IWT(),\\\n",
        "        # nn.Tanh()\n",
        "        ]))\n",
        "    def forward(self,input):\n",
        "        x_enc = self.encoder(input)\n",
        "        x_dec = self.decoder(x_enc)\n",
        "        x_dec = torch.minimum(torch.maximum(torch.zeros_like(x_dec),x_dec),torch.ones_like(x_dec)*500)\n",
        "        # x_dec = torch.nn.functional.relu(x_dec)\n",
        "        return x_dec"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WE1f7XkDa3SJ"
      },
      "outputs": [],
      "source": [
        "model = UDC_Arc(in_ch,num_filters,dilation_rates,nPyramidFilters)\n",
        "model = model.to(device)\n",
        "summary(model,input_size=(3,256,256))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gtiEg3URbP9t"
      },
      "source": [
        "#### Save and Load checkpoint"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MH38Eqyia404"
      },
      "outputs": [],
      "source": [
        "def save_checkpoint(checkpoint_folder,model_type,type='last'):\n",
        "    checkpoint_folder = os.path.join(checkpoint_folder,model_type)\n",
        "    if not os.path.exists(checkpoint_folder):\n",
        "        os.makedirs(checkpoint_folder)\n",
        "    checkpoint_filename = os.path.join(checkpoint_folder,f'{type}.pth')\n",
        "    save_data = {\n",
        "        'step': current_epoch,\n",
        "        f'best_psnr':best_psnr,\n",
        "        f'best_ssim':best_ssim,\n",
        "        'generator_state_dict': model.state_dict(),\n",
        "        'optimizer_state_dict': optimizer.state_dict(),\n",
        "    }\n",
        "    torch.save(save_data, checkpoint_filename)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vr9Om5pdbXnH"
      },
      "outputs": [],
      "source": [
        "def load_model_checkpoint_for_training(checkpoint_folder,model_type,type ='last'):\n",
        "    checkpoint_folder = os.path.join(checkpoint_folder,model_type)\n",
        "    checkpoint_filename = os.path.join(checkpoint_folder, f'{type}.pth')\n",
        "    if not os.path.exists(checkpoint_filename):\n",
        "        print(\"Couldn't find checkpoint file. Starting training from the beginning.\")\n",
        "        return 0,0,0\n",
        "    data = torch.load(checkpoint_filename)\n",
        "    current_epoch = data['step']\n",
        "    best_psnr = data['best_psnr']\n",
        "    best_ssim = data['best_ssim']\n",
        "    model.load_state_dict(data['generator_state_dict'])\n",
        "    optimizer.load_state_dict(data['optimizer_state_dict'])\n",
        "    print(f\"Restored model at epoch {current_epoch}.\")\n",
        "    return best_psnr,best_ssim,current_epoch"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kLZyq9uGbbYF"
      },
      "source": [
        "#### Train and validation Pipeline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HZtb872cbZWO"
      },
      "outputs": [],
      "source": [
        "def train_epoch():\n",
        "    model.train()\n",
        "    for count,(inputs, gt) in enumerate(tqdm.tqdm(train_dataloader)):\n",
        "        inputs = inputs.to(device)\n",
        "        gt = gt.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        with torch.set_grad_enabled(True):\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs,gt)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "    wandb.log({'train_l1_loss':loss.item()})\n",
        "    wandb.log({'Learning rate':optimizer.param_groups[0]['lr']})\n",
        "    return None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sAMMNDR1bdvA"
      },
      "outputs": [],
      "source": [
        "def val_epoch(checkpoint_folder,model_type,best_psnr,best_ssim):\n",
        "    model.eval()\n",
        "    for inputs, gt in tqdm.tqdm(val_dataloader):\n",
        "        inputs = inputs.to(device)\n",
        "        gt = gt.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        with torch.set_grad_enabled(False):\n",
        "            outputs = model(inputs)\n",
        "            _ = criterion(outputs,gt)\n",
        "        psnr.update(outputs,gt)\n",
        "        # ssim.update(outputs,gt)\n",
        "    wandb.log({'val_psnr':psnr.compute().item()})\n",
        "    wandb.log({'val_ssim':ssim.compute().item()})\n",
        "    val_psnr,val_ssim = psnr.compute().item(),ssim.compute().item()\n",
        "    psnr.reset()\n",
        "    ssim.reset()\n",
        "    if val_psnr>best_psnr:\n",
        "        best_psnr = val_psnr\n",
        "        save_checkpoint(checkpoint_folder,model_type,'best')\n",
        "    else:\n",
        "        save_checkpoint(checkpoint_folder,model_type,'last')\n",
        "    if val_ssim>best_ssim:\n",
        "        best_ssim = val_ssim\n",
        "    print(f'Epoch = {current_epoch} Val best PSNR = {best_psnr},Val best SSIM= {best_ssim},Val current PSNR = {val_psnr},Val currentSSIM= {val_ssim}')\n",
        "    return best_psnr,best_ssim"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z-In5_u2bhSE"
      },
      "source": [
        "#### Model Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EPbRXr3vbfe4"
      },
      "outputs": [],
      "source": [
        "current_epoch = 0\n",
        "best_psnr = 0\n",
        "best_ssim = 0\n",
        "# optimizer = torch.optim.SGD(model.parameters(), lr=(batch_size*0.3)/256, momentum=0.9)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=LR, weight_decay=1e-6)\n",
        "criterion = torch.nn.L1Loss().to(device)\n",
        "psnr  = PeakSignalNoiseRatio().to(device)\n",
        "ssim = StructuralSimilarityIndexMeasure().to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ow3czNE8bjDg"
      },
      "outputs": [],
      "source": [
        "best_psnr,best_ssim,current_epoch = load_model_checkpoint_for_training(checkpoint_folder,model_type)\n",
        "wandb.init(project=f\"UDC\",name=log_name)\n",
        "for epoch in range(current_epoch,epochs):\n",
        "    current_epoch = epoch\n",
        "    train_epoch()\n",
        "    best_psnr,best_ssim = val_epoch(checkpoint_folder,model_type,best_psnr,best_ssim)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GcV0NrqbO4b5"
      },
      "source": [
        "#### Test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "from model.DBWN_D import DBWN_D\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "model = DBWN_D(device='cuda:0',num_filters=64)\n",
        "model = model.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "6jEqQV5HxKGo"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "from torchvision.transforms.functional import to_tensor\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "Gukz3B0mO4b5"
      },
      "outputs": [],
      "source": [
        "def test(inp):\n",
        "    output = model(inp)\n",
        "    return output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [],
      "source": [
        "def inv_tone_transform(mapped_x,c=0.25):\n",
        "    im = np.divide((mapped_x*c),(1-mapped_x), out=mapped_x, where=mapped_x!=1)\n",
        "    return im.clip(0,500)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [],
      "source": [
        "def tone_transform(im,c=0.25):\n",
        "    mapped_x = im / (im + c)\n",
        "    return mapped_x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "piSNkk06O4b6"
      },
      "outputs": [],
      "source": [
        "test_dir = 'ds/test/input'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [],
      "source": [
        "# from model.DBWN import DBWN\n",
        "# test_model = DBWN().to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "tlCzhi9BO4b6"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# checkpoint_model_folder = os.path.join(checkpoint_folder,model_type)\n",
        "# checkpoint_filename = os.path.join(checkpoint_model_folder, 'best.pth')\n",
        "checkpoint_filename = 'checkpoint/final.pth'\n",
        "data = torch.load(checkpoint_filename)\n",
        "model.load_state_dict(data['generator_state_dict'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "b9ee6-lgO4b7"
      },
      "outputs": [],
      "source": [
        "image_list = []\n",
        "for dir_path, _, file_names in os.walk(test_dir):\n",
        "    for f_paths in sorted(file_names):\n",
        "        image_list.append(os.path.join(dir_path,f_paths))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "_GCKXCjpDgR9"
      },
      "outputs": [],
      "source": [
        "os.makedirs('ds/test/output',exist_ok = True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "lMfL_8fgO4b7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0 000.npy 64.276764 500.0\n"
          ]
        },
        {
          "ename": "error",
          "evalue": "OpenCV(4.6.0) /io/opencv/modules/imgcodecs/src/loadsave.cpp:730: error: (-2:Unspecified error) could not find a writer for the specified extension in function 'imwrite_'\n",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31merror\u001b[0m                                     Traceback (most recent call last)",
            "\u001b[1;32m/mnt/c/Users/Hrishikesh/Desktop/hrishi/WORK/RESEARCH/2022/journal-2022/UDC/PDCRN_UDC/udc_torch_competition.ipynb Cell 46\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu-20.04/mnt/c/Users/Hrishikesh/Desktop/hrishi/WORK/RESEARCH/2022/journal-2022/UDC/PDCRN_UDC/udc_torch_competition.ipynb#ch0000045vscode-remote?line=11'>12</a>\u001b[0m np\u001b[39m.\u001b[39msave(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mds/test/output/\u001b[39m\u001b[39m{\u001b[39;00mfile_names[count]\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m,out\u001b[39m.\u001b[39mastype(np\u001b[39m.\u001b[39mfloat32))\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu-20.04/mnt/c/Users/Hrishikesh/Desktop/hrishi/WORK/RESEARCH/2022/journal-2022/UDC/PDCRN_UDC/udc_torch_competition.ipynb#ch0000045vscode-remote?line=12'>13</a>\u001b[0m im_save_im \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mconcatenate([[im,out]],axis\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[0;32m---> <a href='vscode-notebook-cell://wsl%2Bubuntu-20.04/mnt/c/Users/Hrishikesh/Desktop/hrishi/WORK/RESEARCH/2022/journal-2022/UDC/PDCRN_UDC/udc_torch_competition.ipynb#ch0000045vscode-remote?line=13'>14</a>\u001b[0m cv2\u001b[39m.\u001b[39;49mimwrite(\u001b[39mf\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mds/test/results/\u001b[39;49m\u001b[39m{\u001b[39;49;00mfile_names[count]\u001b[39m}\u001b[39;49;00m\u001b[39m'\u001b[39;49m,cv2\u001b[39m.\u001b[39;49mcvtColor(im_save_im,cv2\u001b[39m.\u001b[39;49mCOLOR_RGB2BGR))\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu-20.04/mnt/c/Users/Hrishikesh/Desktop/hrishi/WORK/RESEARCH/2022/journal-2022/UDC/PDCRN_UDC/udc_torch_competition.ipynb#ch0000045vscode-remote?line=14'>15</a>\u001b[0m disp \u001b[39m=\u001b[39m [im,out]\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu-20.04/mnt/c/Users/Hrishikesh/Desktop/hrishi/WORK/RESEARCH/2022/journal-2022/UDC/PDCRN_UDC/udc_torch_competition.ipynb#ch0000045vscode-remote?line=15'>16</a>\u001b[0m fig \u001b[39m=\u001b[39m plt\u001b[39m.\u001b[39mfigure(figsize\u001b[39m=\u001b[39m(\u001b[39m12\u001b[39m,\u001b[39m12\u001b[39m))\n",
            "\u001b[0;31merror\u001b[0m: OpenCV(4.6.0) /io/opencv/modules/imgcodecs/src/loadsave.cpp:730: error: (-2:Unspecified error) could not find a writer for the specified extension in function 'imwrite_'\n"
          ]
        }
      ],
      "source": [
        "for count,im_name in enumerate(image_list):\n",
        "    im = np.load(im_name)\n",
        "    # im = tone_transform(im)    \n",
        "    im = torch.from_numpy(tone_transform(im)).unsqueeze(0).permute(0,3,1,2).to(device)\n",
        "    \n",
        "    out = model(im)\n",
        "    out = out[0,...].permute(1,2,0).detach().cpu().numpy()\n",
        "    out = inv_tone_transform(out)\n",
        "    im  = im[0,...].permute(1,2,0).detach().cpu().numpy()\n",
        "    im = inv_tone_transform(im)\n",
        "    print(count,file_names[count],im.max(),out.max())\n",
        "    np.save(f'ds/test/output/{file_names[count]}',out.astype(np.float32))\n",
        "    im_save_im = (np.concatenate([[im,out]],axis=1).clip(0,255)).astype(np.uint8)\n",
        "    cv2.imwrite(f'ds/test/results/{file_names[count]}',cv2.cvtColor(im_save_im,cv2.COLOR_RGB2BGR))\n",
        "    disp = [im,out]\n",
        "    fig = plt.figure(figsize=(12,12))\n",
        "    for i in range(2):\n",
        "        plt.subplot(1,2,i+1)    # the number of images in the grid is 5*5 (25)\n",
        "        plt.imshow(disp[i])\n",
        "    plt.show()\n",
        "    plt.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cywt-E2zPfAS"
      },
      "outputs": [],
      "source": [
        "cd /content/validation/output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jdmkqlWXPgzL"
      },
      "outputs": [],
      "source": [
        "!zip /content/drive/MyDrive/2022/ACCV-22/result.zip -r *"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XXQulZrRPo5J"
      },
      "outputs": [],
      "source": [
        "!wget https://codalab.lisn.upsaclay.fr/my/datasets/download/b549bbbf-7c4e-4ada-bdfb-429523bac284"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vSZKy8NTVVlp"
      },
      "outputs": [],
      "source": [
        "!unzip /content/b549bbbf-7c4e-4ada-bdfb-429523bac284"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JvXTmjPeWt8U"
      },
      "outputs": [],
      "source": [
        "!pip install pyiqa"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KKOKfCbBVb7n"
      },
      "outputs": [],
      "source": [
        "cd /content/test_code"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8HpdHgg-Vv9b"
      },
      "outputs": [],
      "source": [
        "import shutil\n",
        "shutil.copytree('/content/drive/MyDrive/2022/ACCV-22/checkpoint','/content/checkpoint')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rNVp2NmGCM0p"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "background_execution": "on",
      "collapsed_sections": [],
      "machine_shape": "hm",
      "name": "udc_torch_competition.ipynb",
      "private_outputs": true,
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3.9.12 ('yolo')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    },
    "vscode": {
      "interpreter": {
        "hash": "5060ca89b9238f9a359ed787bf32323f9f640022a3623089513147027d65d6a6"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
